{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMHdP9x7AaOi",
        "outputId": "51a1e1d4-dab5-40cb-b923-07e855a82edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s_gu7NgR_mhI"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ThUp9pbB_mhJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDOWs2c3_mhK"
      },
      "source": [
        "<h2>Creating Spark Session</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "68OBNVzT_mhL"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder \\\n",
        "  .appName(\"Sentiment Analysis\") \\\n",
        "  .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1HrRvxq_mhL"
      },
      "source": [
        "This will create our spark session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7PP5f6lA_mhL"
      },
      "outputs": [],
      "source": [
        "# Loading the data file\n",
        "tweets_df = spark.read.csv(r\"Sentiment Analysis Dataset.csv\", inferSchema=True, header=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FinWXLAn_mhL",
        "outputId": "89a584d6-4ab3-4d24-ae12-7e0daef6942f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+---------------+--------------------+\n",
            "|ItemID|Sentiment|SentimentSource|       SentimentText|\n",
            "+------+---------+---------------+--------------------+\n",
            "|     1|        0|   Sentiment140|                 ...|\n",
            "|     2|        0|   Sentiment140|                 ...|\n",
            "|     3|        1|   Sentiment140|              omg...|\n",
            "|     4|        0|   Sentiment140|          .. Omga...|\n",
            "|     5|        0|   Sentiment140|         i think ...|\n",
            "|     6|        0|   Sentiment140|         or i jus...|\n",
            "+------+---------+---------------+--------------------+\n",
            "only showing top 6 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tweets_df.show(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_8omuFk_mhM",
        "outputId": "a760b4fc-545c-41ce-f2e1-09262111ce8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, ItemID: string, Sentiment: string, SentimentSource: string, SentimentText: string]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tweets_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN5JeyAH_mhM"
      },
      "source": [
        "<h2>Cleaning the data</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9abfq193_mhN"
      },
      "source": [
        "<h3>Converting the text to lowercase</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rolsOimT_mhN"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import lower\n",
        "\n",
        "tweets_df = tweets_df.withColumn(\"text\", lower(tweets_df.SentimentText))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFoJs7hp_mhN"
      },
      "source": [
        "<h3>Checking for duplicates</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88eb03Pt_mhN",
        "outputId": "d6dc7255-d525-4944-9a82-6e3824f33fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate rows: 0\n"
          ]
        }
      ],
      "source": [
        "# Considering all columns\n",
        "duplicates = tweets_df.dropDuplicates()\n",
        "num_duplicates = tweets_df.count() - duplicates.count()\n",
        "print(f\"Number of duplicate rows: {num_duplicates}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6-Sm5te_mhO"
      },
      "source": [
        "<h3>Checking for missing values</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J2ODoBwO_mhO"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--CxJR0U_mhP",
        "outputId": "72bc52dd-47b4-4b91-a035-0e121463286a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with missing values:\n",
            "+-------------+\n",
            "|SentimentText|\n",
            "+-------------+\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import count\n",
        "\n",
        "missing_counts = tweets_df.groupBy(\"SentimentText\").agg(count(\"SentimentText\").alias(\"count\")).where(col(\"count\") == 0)\n",
        "missing_cols = missing_counts.select(\"SentimentText\")\n",
        "\n",
        "print(\"Columns with missing values:\")\n",
        "missing_cols.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwDhePKJ_mhP",
        "outputId": "18e4228b-67fa-4846-e46f-0875827de94a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "missing_cols.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYqWUPrz_mhQ"
      },
      "source": [
        "<p>There are no missing values or duplicate values in the dataset</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VASpNWZD_mhQ"
      },
      "source": [
        "<h2>Selecting the related data</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcuwceik_mhQ",
        "outputId": "5a9abc65-4002-48d8-b954-eccf0830e962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|SentimentText                                                                                                                       |label|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|                     is so sad for my APL friend.............                                                                       |0    |\n",
            "|                   I missed the New Moon trailer...                                                                                 |0    |\n",
            "|              omg its already 7:30 :O                                                                                               |1    |\n",
            "|          .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...|0    |\n",
            "|         i think mi bf is cheating on me!!!       T_T                                                                               |0    |\n",
            "|         or i just worry too much?                                                                                                  |0    |\n",
            "|       Juuuuuuuuuuuuuuuuussssst Chillin!!                                                                                           |1    |\n",
            "|       Sunny Again        Work Tomorrow  :-|       TV Tonight                                                                       |0    |\n",
            "|      handed in my uniform today . i miss you already                                                                               |1    |\n",
            "|      hmmmm.... i wonder how she my number @-)                                                                                      |1    |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentiment_data = tweets_df.select(\"SentimentText\", col(\"Sentiment\").cast(\"Int\").alias(\"label\"))\n",
        "sentiment_data.show(truncate = False,n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3jOwWlx_mhQ"
      },
      "source": [
        "<p>Dividing the data into training data and test data</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ueKYxD1_mhR",
        "outputId": "d6090537-fb40-4886-c573-cd9fc542f4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data rows: 1105272 ; Testing data rows: 473355\n"
          ]
        }
      ],
      "source": [
        "#divide data, 70% for training, 30% for testing\n",
        "train_test_data = sentiment_data.randomSplit([0.7, 0.3])\n",
        "sentiment_train_data = train_test_data[0] #index 0 = data training\n",
        "sentiment_test_data = train_test_data[1] #index 1 = data testing\n",
        "training_data = sentiment_train_data.count()\n",
        "testing_data = sentiment_test_data.count()\n",
        "print (\"Training data rows:\", training_data, \"; Testing data rows:\", testing_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Sd_3Vt4_mhR"
      },
      "source": [
        "<h2>Preparing training data</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RYWXPOz8_mhR"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXkOGyg2_mhS",
        "outputId": "79cd6274-4b88-4fc1-a3d1-c4f954f415e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------+\n",
            "|SentimentText                                                              |label|SentimentWords                                                                                                |\n",
            "+---------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------+\n",
            "|                                     I miss her so much already...         |0    |[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , i, miss, her, so, much, already...]|\n",
            "|                     is so sad for my APL friend.............              |0    |[, , , , , , , , , , , , , , , , , , , , , is, so, sad, for, my, apl, friend.............]                    |\n",
            "|                   I missed the New Moon trailer...                        |0    |[, , , , , , , , , , , , , , , , , , , i, missed, the, new, moon, trailer...]                                 |\n",
            "|               just practising.....how I feel                              |0    |[, , , , , , , , , , , , , , , just, practising.....how, i, feel]                                             |\n",
            "|             i just want to hear from you. i guess that's asking too much..|0    |[, , , , , , , , , , , , , i, just, want, to, hear, from, you., i, guess, that's, asking, too, much..]        |\n",
            "+---------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(inputCol=\"SentimentText\", outputCol=\"SentimentWords\")\n",
        "tokenize_train_data = tokenizer.transform(sentiment_train_data)\n",
        "tokenize_train_data.show(truncate=False, n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DooUD5BA_mhS"
      },
      "source": [
        "<p>Removing Stop Words</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MDEJEv4N_mhS"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StopWordsRemover"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYUb2OHT_mhS",
        "outputId": "6af443dd-f8b5-457d-a284-b51211a516e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
            "|SentimentText                                                              |label|SentimentWords                                                                                                |MeaningfulWords                                                                                   |\n",
            "+---------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
            "|                                     I miss her so much already...         |0    |[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , i, miss, her, so, much, already...]|[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , miss, much, already...]|\n",
            "|                     is so sad for my APL friend.............              |0    |[, , , , , , , , , , , , , , , , , , , , , is, so, sad, for, my, apl, friend.............]                    |[, , , , , , , , , , , , , , , , , , , , , sad, apl, friend.............]                         |\n",
            "|                   I missed the New Moon trailer...                        |0    |[, , , , , , , , , , , , , , , , , , , i, missed, the, new, moon, trailer...]                                 |[, , , , , , , , , , , , , , , , , , , missed, new, moon, trailer...]                             |\n",
            "|               just practising.....how I feel                              |0    |[, , , , , , , , , , , , , , , just, practising.....how, i, feel]                                             |[, , , , , , , , , , , , , , , practising.....how, feel]                                          |\n",
            "|             i just want to hear from you. i guess that's asking too much..|0    |[, , , , , , , , , , , , , i, just, want, to, hear, from, you., i, guess, that's, asking, too, much..]        |[, , , , , , , , , , , , , want, hear, you., guess, asking, much..]                               |\n",
            "+---------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "stop_words_removal = StopWordsRemover(inputCol=tokenizer.getOutputCol(),\n",
        "                       outputCol=\"MeaningfulWords\")\n",
        "train_data_stopword_removed = stop_words_removal.transform(tokenize_train_data)\n",
        "train_data_stopword_removed.show(truncate=False, n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNh5ecfZ_mhT"
      },
      "source": [
        "<p>Now converting words into numbers using Austin Appleby's MurmurHash 3 Algorithm</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "41J8xtBr_mhT"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import HashingTF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo4vR0TA_mhT",
        "outputId": "6fcabdf4-d754-4458-fd15-995ef406aab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------------------------------------------------------------------------------------+-------------------------------------------------------------------+\n",
            "|label|MeaningfulWords                                                                                   |features                                                           |\n",
            "+-----+--------------------------------------------------------------------------------------------------+-------------------------------------------------------------------+\n",
            "|0    |[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , miss, much, already...]|(262144,[76764,232735,249180,260036],[1.0,1.0,37.0,1.0])           |\n",
            "|0    |[, , , , , , , , , , , , , , , , , , , , , sad, apl, friend.............]                         |(262144,[23825,74989,125638,249180],[1.0,1.0,1.0,21.0])            |\n",
            "|0    |[, , , , , , , , , , , , , , , , , , , missed, new, moon, trailer...]                             |(262144,[89833,165360,201103,244504,249180],[1.0,1.0,1.0,1.0,19.0])|\n",
            "+-----+--------------------------------------------------------------------------------------------------+-------------------------------------------------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "hashTF = HashingTF(inputCol=stop_words_removal.getOutputCol(), outputCol=\"features\")\n",
        "numericTrainData = hashTF.transform(train_data_stopword_removed).select(\n",
        "    'label', 'MeaningfulWords', 'features')\n",
        "numericTrainData.show(truncate=False, n=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n"
      ],
      "metadata": {
        "id": "OHPWKORAa3lI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, training_data, param_grid):\n",
        "    \"\"\"\n",
        "    Trains a model with hyperparameter tuning and returns the best model and its evaluation metrics.\n",
        "\n",
        "    Args:\n",
        "        model: Spark machine learning model object.\n",
        "        training_data: Spark DataFrame containing training data.\n",
        "        param_grid: ParamGridBuilder object defining the hyperparameter search space.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the best trained model and its evaluation metrics (accuracy).\n",
        "    \"\"\"\n",
        "    # Define the evaluator for multi-class classification\n",
        "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "    # Create the CrossValidator for hyperparameter tuning with 3-fold cross-validation (adjust folds as needed)\n",
        "    cv = CrossValidator(estimator=model, evaluator=evaluator, estimatorParamMaps=param_grid, numFolds=3)\n",
        "\n",
        "    # Train the model with hyperparameter tuning\n",
        "    best_model = cv.fit(training_data)\n",
        "\n",
        "    # Evaluate the best model on the entire training data\n",
        "    accuracy = evaluator.evaluate(best_model.bestModel.transform(training_data))\n",
        "\n",
        "    return best_model, accuracy"
      ],
      "metadata": {
        "id": "Ne8gldxZC8W4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dGsLXhxd1quX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQUl17YEu5JV",
        "outputId": "4299dd00-d7d9-436c-c225-a0fd0ac15cb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Accuracy: 0.8637992975612889\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "possible_labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "svm = LinearSVC(maxIter=100, regParam=0.01)  #\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "param_grid = ParamGridBuilder().build()\n",
        "\n",
        "# Train and evaluate SVM with hyperparameter tuning\n",
        "best_svm_model, svm_accuracy = train_and_evaluate(svm, numericTrainData, param_grid)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(\"Best SVM Accuracy:\", svm_accuracy)\n",
        "\n",
        "\n",
        "model_path_drive = \"/content/gdrive/MyDrive/Datasets/spark_ml_model\"\n",
        "\n",
        "# Save the model\n",
        "best_svm_model.bestModel.save(model_path_drive)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\",\n",
        "                        maxIter=10, regParam=0.01)\n",
        "#model = lr.fit(numericTrainData)\n",
        "param_grid = ParamGridBuilder().build()\n",
        "\n",
        "best_lr_model, lr_accuracy = train_and_evaluate(lr, numericTrainData, param_grid)\n",
        "print (\"Training is done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JLKsSOE8Xbu",
        "outputId": "7be44f6a-ce83-4e44-94f2-f5744dcb2a9a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training is done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best lr Accuracy:\", lr_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJDQl6AWEess",
        "outputId": "f38d4d86-b3f4-4a15-e3e7-b44e92a3e892"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best lr Accuracy: 0.8618769931434351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best SVM Accuracy:\", svm_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0El0HEZU0YsD",
        "outputId": "ddda35e6-3ab2-4e5d-8b21-b051ebd1b527"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Accuracy: 0.8637992975612889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as plt"
      ],
      "metadata": {
        "id": "9bBLUSVi-FKp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXaBYtfa_mhV"
      },
      "source": [
        "</h2>Prepare testing data</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "cyVD0g9s_mhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a6e391-ab0b-42ba-8f81-5fb07c95f585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
            "|Label|MeaningfulWords                                                                                  |features                                                                                           |\n",
            "+-----+-------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
            "|0    |[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , exhausted]|(262144,[148003,249180],[1.0,43.0])                                                                |\n",
            "|0    |[, , , , , , , , , , , , , , , noooooooooo, friends, twitter, makes, sad, someone, follow]       |(262144,[1512,125638,130047,148039,182401,199581,213767,249180],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,15.0])|\n",
            "+-----+-------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_tokens = tokenizer.transform(sentiment_test_data)\n",
        "test_data_stop_words_removed = stop_words_removal.transform(test_tokens)\n",
        "numericTest = hashTF.transform(test_data_stop_words_removed).select(\n",
        "    'Label', 'MeaningfulWords', 'features')\n",
        "numericTest.show(truncate=False, n=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXq3Kyrl_mhW"
      },
      "source": [
        "<h2>Prediction</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "AWGFKw_Y_mhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c71d75c0-3f1c-4232-e699-082834206f2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------+----------+-----+\n",
            "|MeaningfulWords                                                                                  |prediction|Label|\n",
            "+-------------------------------------------------------------------------------------------------+----------+-----+\n",
            "|[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , exhausted]|0.0       |0    |\n",
            "|[, , , , , , , , , , , , , , , noooooooooo, friends, twitter, makes, sad, someone, follow]       |0.0       |0    |\n",
            "|[, , , , , , , , , , , , , , omg, already, 7:30, :o]                                             |0.0       |1    |\n",
            "|[, , , , , , , , , , life, lazzzzyyyy!!!!!!!, , , , , , , , , , , , ***********]                 |0.0       |1    |\n",
            "|[, , , , , , , , heart, hurts, badly...]                                                         |0.0       |0    |\n",
            "|[, , , , , , , , wish, ella, somebody,,,,]                                                       |0.0       |0    |\n",
            "|[, , , , , , , juuuuuuuuuuuuuuuuussssst, chillin!!]                                              |1.0       |1    |\n",
            "|[, , , , , , thanks, haters, face, day!, 112-102]                                                |1.0       |1    |\n",
            "|[, , , , , , weekend, sucked, far]                                                               |0.0       |0    |\n",
            "|[, , , , , &lt;-, mustache, man, desperate]                                                      |0.0       |0    |\n",
            "|[, , , , , @riceuniversiity, know, huh, @kouture85, im, bout, cry@ahmier, thanks, marco!, *muah*]|1.0       |0    |\n",
            "|[, , , , , dont, like, weekend.., huhuhu, (, (]                                                  |0.0       |0    |\n",
            "|[, , , , , get, right, away!]                                                                    |0.0       |0    |\n",
            "|[, , , , , angry]                                                                                |0.0       |0    |\n",
            "|[, , , , , ok, thats, win.]                                                                      |0.0       |0    |\n",
            "|[, , , , , praise, god, beautiful, day!!!]                                                       |1.0       |1    |\n",
            "|[, , , , !bye, everyone!]                                                                        |0.0       |1    |\n",
            "|[, , , , &lt;--------, way, feel, right, now...]                                                 |1.0       |0    |\n",
            "|[, , , , bye, world!!!!!!]                                                                       |1.0       |0    |\n",
            "|[, , , , sickness., strike, say, strike!, ohhhh, well,, 'nother, day, school, guess]             |1.0       |0    |\n",
            "+-------------------------------------------------------------------------------------------------+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "correct prediction: 350702 , total data: 473355 , accuracy: 0.7408858045230324\n"
          ]
        }
      ],
      "source": [
        "prediction_model = best_svm_model.transform(numericTest)\n",
        "prediction_final = prediction_model.select(\n",
        "    \"MeaningfulWords\", \"prediction\", \"Label\")\n",
        "prediction_final.show(n=20, truncate = False)\n",
        "prediction = prediction_final.filter(\n",
        "    prediction_final['prediction'] == prediction_final['Label']).count()\n",
        "data = prediction_final.count()\n",
        "print(\"correct prediction:\", prediction, \", total data:\", data,\n",
        "      \", accuracy:\", prediction/data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_model_lr = best_lr_model.transform(numericTest)\n",
        "prediction_final_lr = prediction_model.select(\n",
        "    \"MeaningfulWords\", \"prediction\", \"Label\")\n",
        "prediction_final_lr.show(n=20, truncate = False)\n",
        "prediction_lr = prediction_final_lr.filter(\n",
        "    prediction_final_lr['prediction'] == prediction_final_lr['Label']).count()\n",
        "data_lr = prediction_final_lr.count()\n",
        "print(\"correct prediction:\", prediction_lr, \", total data:\", data,\n",
        "      \", accuracy:\", prediction_lr/data_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vMDEEDgBrMY",
        "outputId": "379f0d26-de2d-493b-c82e-b1d889dc7ffa"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------+----------+-----+\n",
            "|MeaningfulWords                                                                                  |prediction|Label|\n",
            "+-------------------------------------------------------------------------------------------------+----------+-----+\n",
            "|[, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , exhausted]|0.0       |0    |\n",
            "|[, , , , , , , , , , , , , , , noooooooooo, friends, twitter, makes, sad, someone, follow]       |0.0       |0    |\n",
            "|[, , , , , , , , , , , , , , omg, already, 7:30, :o]                                             |0.0       |1    |\n",
            "|[, , , , , , , , , , life, lazzzzyyyy!!!!!!!, , , , , , , , , , , , ***********]                 |0.0       |1    |\n",
            "|[, , , , , , , , heart, hurts, badly...]                                                         |0.0       |0    |\n",
            "|[, , , , , , , , wish, ella, somebody,,,,]                                                       |0.0       |0    |\n",
            "|[, , , , , , , juuuuuuuuuuuuuuuuussssst, chillin!!]                                              |1.0       |1    |\n",
            "|[, , , , , , thanks, haters, face, day!, 112-102]                                                |1.0       |1    |\n",
            "|[, , , , , , weekend, sucked, far]                                                               |0.0       |0    |\n",
            "|[, , , , , &lt;-, mustache, man, desperate]                                                      |0.0       |0    |\n",
            "|[, , , , , @riceuniversiity, know, huh, @kouture85, im, bout, cry@ahmier, thanks, marco!, *muah*]|1.0       |0    |\n",
            "|[, , , , , dont, like, weekend.., huhuhu, (, (]                                                  |0.0       |0    |\n",
            "|[, , , , , get, right, away!]                                                                    |0.0       |0    |\n",
            "|[, , , , , angry]                                                                                |0.0       |0    |\n",
            "|[, , , , , ok, thats, win.]                                                                      |0.0       |0    |\n",
            "|[, , , , , praise, god, beautiful, day!!!]                                                       |1.0       |1    |\n",
            "|[, , , , !bye, everyone!]                                                                        |0.0       |1    |\n",
            "|[, , , , &lt;--------, way, feel, right, now...]                                                 |1.0       |0    |\n",
            "|[, , , , bye, world!!!!!!]                                                                       |1.0       |0    |\n",
            "|[, , , , sickness., strike, say, strike!, ohhhh, well,, 'nother, day, school, guess]             |1.0       |0    |\n",
            "+-------------------------------------------------------------------------------------------------+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "correct prediction: 350702 , total data: 473355 , accuracy: 0.7408858045230324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml import PipelineModel\n",
        "\n",
        "# Assuming you have the trained model object available in your notebook\n",
        "loaded_model = best_svm_model.bestModel\n",
        "\n",
        "def preprocess_tweet(tweet):\n",
        "    # Create a DataFrame with a single column named \"SentimentText\" containing the tweet\n",
        "    tweet_df = spark.createDataFrame([(tweet,)], [\"SentimentText\"])\n",
        "\n",
        "    # Tokenize the tweet\n",
        "    tokens = tokenizer.transform(tweet_df)\n",
        "\n",
        "    # Remove stop words\n",
        "    words_removed = stop_words_removal.transform(tokens)\n",
        "\n",
        "    # Convert to features\n",
        "    features = hashTF.transform(words_removed).select(\"SentimentText\", \"features\")\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "\n",
        "def predict_sentiment(tweet):\n",
        "    # Preprocess the tweet\n",
        "    tweet_features = preprocess_tweet(tweet)\n",
        "\n",
        "    # Use the model to predict sentiment\n",
        "    prediction_model = loaded_model.transform(tweet_features)\n",
        "\n",
        "    # Extract prediction label\n",
        "    prediction_label = prediction_model.select(\"prediction\").collect()[0][0]\n",
        "\n",
        "    return prediction_label\n",
        "\n",
        "# Get input tweet from user\n",
        "tweet_input = input(\"Enter your tweet: \")\n",
        "\n",
        "# Predict sentiment label\n",
        "predicted_label = predict_sentiment(tweet_input)\n",
        "\n",
        "print(\"Predicted sentiment label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZFkPDF4FbXy",
        "outputId": "4b9008e6-ebd8-4aee-c186-39c2836a94e6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your tweet: We should send rockets not at each other, but rather to the stars\n",
            "Predicted sentiment label: 1.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}